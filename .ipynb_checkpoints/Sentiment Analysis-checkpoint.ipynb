{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.288462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Works great especially going grocery store</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     App                                  Translated_Review  \\\n",
       "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
       "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
       "2  10 Best Foods for You                                                NaN   \n",
       "3  10 Best Foods for You         Works great especially going grocery store   \n",
       "4  10 Best Foods for You                                       Best idea us   \n",
       "\n",
       "  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "0  Positive                1.00                0.533333  \n",
       "1  Positive                0.25                0.288462  \n",
       "2       NaN                 NaN                     NaN  \n",
       "3  Positive                0.40                0.875000  \n",
       "4  Positive                1.00                0.300000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"googleplaystore_user_reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    23998\n",
       "Negative     8271\n",
       "Neutral      5163\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26863"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64295 entries, 0 to 64294\n",
      "Data columns (total 5 columns):\n",
      "App                       64295 non-null object\n",
      "Translated_Review         37427 non-null object\n",
      "Sentiment                 37432 non-null object\n",
      "Sentiment_Polarity        37432 non-null float64\n",
      "Sentiment_Subjectivity    37432 non-null float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentatively, I am removing the rows with NaN values for the reviews. I cannot run a sentiment analysis if the reviews are missing. I will try and see if there is a way to impute these later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.288462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Works great especially going grocery store</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best way</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     App                                  Translated_Review  \\\n",
       "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
       "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
       "3  10 Best Foods for You         Works great especially going grocery store   \n",
       "4  10 Best Foods for You                                       Best idea us   \n",
       "5  10 Best Foods for You                                           Best way   \n",
       "\n",
       "  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "0  Positive                1.00                0.533333  \n",
       "1  Positive                0.25                0.288462  \n",
       "3  Positive                0.40                0.875000  \n",
       "4  Positive                1.00                0.300000  \n",
       "5  Positive                1.00                0.300000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37427 entries, 0 to 64230\n",
      "Data columns (total 5 columns):\n",
      "App                       37427 non-null object\n",
      "Translated_Review         37427 non-null object\n",
      "Sentiment                 37427 non-null object\n",
      "Sentiment_Polarity        37427 non-null float64\n",
      "Sentiment_Subjectivity    37427 non-null float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    23998\n",
       "Negative     8271\n",
       "Neutral      5158\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "I lost 5 Neutral reviews. Other than that, the other figures remained the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bowmasters                                            312\n",
       "Helix Jump                                            273\n",
       "Angry Birds Classic                                   273\n",
       "Calorie Counter - MyFitnessPal                        254\n",
       "Candy Crush Saga                                      240\n",
       "Duolingo: Learn Languages Free                        240\n",
       "Garena Free Fire                                      222\n",
       "8 Ball Pool                                           219\n",
       "Calorie Counter - Macros                              200\n",
       "10 Best Foods for You                                 194\n",
       "CBS Sports App - Scores, News, Stats & Watch Live     192\n",
       "Google Photos                                         191\n",
       "Alto's Adventure                                      175\n",
       "8fit Workouts & Meal Planner                          171\n",
       "DRAGON BALL LEGENDS                                   167\n",
       "Candy Crush Soda Saga                                 166\n",
       "Clash Royale                                          165\n",
       "Adobe Acrobat Reader                                  162\n",
       "Episode - Choose Your Story                           160\n",
       "Block Puzzle                                          154\n",
       "Flow Free                                             154\n",
       "Bubble Shooter                                        145\n",
       "Calorie Counter - MyNetDiary                          139\n",
       "Agar.io                                               136\n",
       "Calorie Counter & Diet Tracker                        135\n",
       "Cooking Fever                                         135\n",
       "Galaxy Attack: Alien Shooter                          134\n",
       "Gardenscapes                                          133\n",
       "Colorfy: Coloring Book for Adults - Free              133\n",
       "Facebook                                              132\n",
       "                                                     ... \n",
       "Google Primer                                           2\n",
       "Dashlane Free Password Manager                          2\n",
       "Extreme Car Driving Simulator                           2\n",
       "Calculator Plus Free                                    2\n",
       "Calculator with Percent (Free)                          2\n",
       "DashClock Widget                                        1\n",
       "GPS Map Free                                            1\n",
       "Drawing for Kids Learning Games for Toddlers age 3      1\n",
       "CBS News                                                1\n",
       "HD Camera                                               1\n",
       "Draw a Stickman: EPIC 2                                 1\n",
       "Draw In                                                 1\n",
       "Discover Mobile                                         1\n",
       "Bed Time Fan - White Noise Sleep Sounds                 1\n",
       "Best Ovulation Tracker Fertility Calendar App Glow      1\n",
       "Google Slides                                           1\n",
       "Caf - Mon Compte                                        1\n",
       "Draw A Stickman                                         1\n",
       "CallApp: Caller ID, Blocker & Phone Call Recorder       1\n",
       "Free Live Talk-Video Call                               1\n",
       "Calculator - unit converter                             1\n",
       "Fruit Block - Puzzle Legend                             1\n",
       "Daily Workouts - Exercise Fitness Routine Trainer       1\n",
       "All-in-One Mahjong 3 FREE                               1\n",
       "Caller ID +                                             1\n",
       "HomeWork                                                1\n",
       "Calendar+ Schedule Planner App                          1\n",
       "Best Fiends - Free Puzzle Game                          1\n",
       "Apartment Decorating Ideas                              1\n",
       "Google Trips - Travel Planner                           1\n",
       "Name: App, Length: 865, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.App.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1074 apps in this list, with at least 30 reviews in each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     i like eat delicious food thats im cooking foo...\n",
       "1       this help eating healthy exercise regular basis\n",
       "3            works great especially going grocery store\n",
       "4                                          best idea us\n",
       "5                                              best way\n",
       "6                                               amazing\n",
       "8                                   looking forward app\n",
       "9                   it helpful site  it help foods get \n",
       "10                                             good you\n",
       "11    useful information the amount spelling errors ...\n",
       "Name: Translated_Review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "replace_wo_space = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "replace_with_space = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "reviews = df['Translated_Review'].str.replace(replace_wo_space,'').str.lower()\n",
    "reivews = reviews.str.replace(replace_with_space,'')\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.288462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Works great especially going grocery store</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best way</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     App                                  Translated_Review  \\\n",
       "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
       "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
       "3  10 Best Foods for You         Works great especially going grocery store   \n",
       "4  10 Best Foods for You                                       Best idea us   \n",
       "5  10 Best Foods for You                                           Best way   \n",
       "\n",
       "   Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "0          2                1.00                0.533333  \n",
       "1          2                0.25                0.288462  \n",
       "3          2                0.40                0.875000  \n",
       "4          2                1.00                0.300000  \n",
       "5          2                1.00                0.300000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'] = df['Sentiment'].map({'Positive': 2, 'Neutral': 1, 'Negative':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37427"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37427"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37427, 23545)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews)\n",
    "X = cv.transform(reviews)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each review has been converted into a group of integers that allows the program to access the words using the corresponding integers, i.e. it creates a dictionary of some sort, and reads in the words from there. This way, it does not have to deal with the words directly, and it will be easier for the model to read in those words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = df['Sentiment']\n",
    "#target = pd.get_dummies(df['Sentiment'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sentiment Analysis using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[0.25, 0.5, 0.75, 1], class_weight=None, cv=5,\n",
       "           dual=False, fit_intercept=True, intercept_scaling=1.0,\n",
       "           max_iter=100, multi_class='multinomial', n_jobs=None,\n",
       "           penalty='l2', random_state=42, refit=True, scoring=None,\n",
       "           solver='newton-cg', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "grid_params = [0.25, 0.5, 0.75, 1]\n",
    "lr = LogisticRegressionCV(Cs=grid_params, solver='newton-cg', cv=5, multi_class='multinomial', random_state=42)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot use the default solver, liblinear, because this is a multiclass problem, i.e. the target variable is not binary; it can be used to classify the review as 'positive', 'neutral' or 'negative'.\n",
    "We use the 'newton-cg' solver, because we're interested in using the 'l2' regularizer. We would, however, shift to the 'saga' problem if we are slightly underfitted. The Ridge regularizer is used right now because it always gives a definite answer, unlike Lasso, which is slightly more generalized, and may give multiple answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[0.91223049, 0.91700057, 0.92043503, 0.92386949],\n",
       "        [0.90954198, 0.91545802, 0.91832061, 0.91927481],\n",
       "        [0.91240458, 0.91717557, 0.91965649, 0.91984733],\n",
       "        [0.92154991, 0.92498568, 0.92689445, 0.92765795],\n",
       "        [0.91523482, 0.91733486, 0.92038946, 0.92134402]]),\n",
       " 1: array([[0.91223049, 0.91700057, 0.92043503, 0.92386949],\n",
       "        [0.90954198, 0.91545802, 0.91832061, 0.91927481],\n",
       "        [0.91240458, 0.91717557, 0.91965649, 0.91984733],\n",
       "        [0.92154991, 0.92498568, 0.92689445, 0.92765795],\n",
       "        [0.91523482, 0.91733486, 0.92038946, 0.92134402]]),\n",
       " 2: array([[0.91223049, 0.91700057, 0.92043503, 0.92386949],\n",
       "        [0.90954198, 0.91545802, 0.91832061, 0.91927481],\n",
       "        [0.91240458, 0.91717557, 0.91965649, 0.91984733],\n",
       "        [0.92154991, 0.92498568, 0.92689445, 0.92765795],\n",
       "        [0.91523482, 0.91733486, 0.92038946, 0.92134402]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.9856095885182075\n",
      "Testing accuracy is 0.9283996794015495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "print(\"Training accuracy is {}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "print(\"Testing accuracy is {}\".format(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['this is a terrible app','i love this app', 'more to be expected'])\n",
    "s = cv.transform(s)\n",
    "lr.predict(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis, we can see that it has identified the thir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Remove stop words, i.e. he,she,they"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    like eat delicious food thats im cooking food ...\n",
       "1           help eating healthy exercise regular basis\n",
       "3           works great especially going grocery store\n",
       "4                                         best idea us\n",
       "5                                             best way\n",
       "Name: Translated_Review, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "heshe = stopwords.words('english')\n",
    "reviews_stopworded = reviews.apply(lambda x: ' '.join([word for word in x.split()\n",
    "                                                          if word not in heshe]))\n",
    "reviews_stopworded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Normalization through Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    like eat delicious food thats im cooking food ...\n",
       "1           help eating healthy exercise regular basis\n",
       "3            work great especially going grocery store\n",
       "4                                          best idea u\n",
       "5                                             best way\n",
       "Name: Translated_Review, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "reviews_lem = reviews_stopworded.apply(lambda x: ' '.join([lem.lemmatize(word) for word in x.split()]))\n",
    "reviews_lem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_cv = CountVectorizer(binary=True, ngram_range=(1,2))\n",
    "ngram_cv.fit(reviews_lem)\n",
    "X = ngram_cv.transform(reviews_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# grid_params = [0.25, 0.5, 0.75, 1]\n",
    "# lr_nltk = LogisticRegressionCV(Cs=grid_params, solver='newton-cg', cv=5, multi_class='multinomial', random_state=42)\n",
    "# lr_nltk.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_nltk = LogisticRegression(solver='newton-cg', multi_class='multinomial', C=1.0, random_state=42)\n",
    "lr_nltk.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.9945797389113673\n",
      "Testing accuracy is 0.919405111764182\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr_nltk.predict(X_train)\n",
    "print(\"Training accuracy is {}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = lr_nltk.predict(X_test)\n",
    "print(\"Testing accuracy is {}\".format(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['this is a terrible app', 'i love this app', 'more to be expected'])\n",
    "s = ngram_cv.transform(s)\n",
    "lr_nltk.predict(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK with Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=2500,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.25, 0.5, 0.75, 1.0]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = {'C':[0.25,0.5,0.75,1.0]}\n",
    "svm = GridSearchCV(LinearSVC(multi_class='ovr', max_iter=2500, random_state=42),grid_params,cv=5)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.33812947, 6.98477254, 9.5795547 , 9.4163734 ]),\n",
       " 'std_fit_time': array([0.8104096 , 1.7152252 , 1.93701435, 0.72884227]),\n",
       " 'mean_score_time': array([0.00654416, 0.00704088, 0.00624142, 0.00626078]),\n",
       " 'std_score_time': array([0.00206647, 0.00110341, 0.00110827, 0.00209564]),\n",
       " 'param_C': masked_array(data=[0.25, 0.5, 0.75, 1.0],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.25}, {'C': 0.5}, {'C': 0.75}, {'C': 1.0}],\n",
       " 'split0_test_score': array([0.91203969, 0.91032246, 0.90917764, 0.90803282]),\n",
       " 'split1_test_score': array([0.91183206, 0.91221374, 0.91183206, 0.91183206]),\n",
       " 'split2_test_score': array([0.91335878, 0.9139313 , 0.91354962, 0.91278626]),\n",
       " 'split3_test_score': array([0.91735064, 0.91506013, 0.91601451, 0.91677801]),\n",
       " 'split4_test_score': array([0.91714395, 0.91828942, 0.91714395, 0.91466208]),\n",
       " 'mean_test_score': array([0.91434461, 0.9139629 , 0.91354302, 0.91281777]),\n",
       " 'std_test_score': array([0.00242769, 0.00269199, 0.00286564, 0.0029311 ]),\n",
       " 'rank_test_score': array([1, 2, 3, 4]),\n",
       " 'split0_train_score': array([0.99661211, 0.9977096 , 0.99804361, 0.99804361]),\n",
       " 'split1_train_score': array([0.99661227, 0.99785285, 0.99799599, 0.99804371]),\n",
       " 'split2_train_score': array([0.99685084, 0.99766199, 0.99780513, 0.99794828]),\n",
       " 'split3_train_score': array([0.99666015, 0.99790066, 0.99813922, 0.99837779]),\n",
       " 'split4_train_score': array([0.99642176, 0.9976145 , 0.99813931, 0.99823473]),\n",
       " 'mean_train_score': array([0.99663143, 0.99774792, 0.99802466, 0.99812962]),\n",
       " 'std_train_score': array([0.00013687, 0.00011045, 0.000123  , 0.00015511])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9143446064585082"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.25, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=2500,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is 0.996450110695473\n",
      "Testing accuracy is 0.9218096001424883\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = svm.predict(X_train)\n",
    "print(\"Training accuracy is {}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "\n",
    "y_test_pred = svm.predict(X_test)\n",
    "print(\"Testing accuracy is {}\".format(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['this is a terrible app', 'i love this app', 'more to be expected'])\n",
    "s = ngram_cv.transform(s)\n",
    "svm.predict(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ngram_cv as the model for the X&y-values because they're under the same X_train, y_train models that was used to transform the data for the LinearSVC model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 methods we used to perform sentiment analysis here.\n",
    "\n",
    "1. Logistic Regression\n",
    "2. NLTK pre-processing<br />\n",
    "    a. Logistic Regression<br />\n",
    "    b. Linear SVM\n",
    "\n",
    "NOTE: This was a multi-class classification analysis.\n",
    "\n",
    "### Reasonings\n",
    "\n",
    "In Logistic Regression, since this was a multi-class classification, we changed the solver from the default 'liblinear' to 'newton-cg'. We had the option of using other solvers, but the focus was on using the 'l2' penalty since there were limited  features. I would have used 'saga' if we had more multiple features.\n",
    "\n",
    "Trying to improve upon the model, the data was pre-processed using the Natural Language Toolkit. There are 2 things done here that differed it from the above model. The first was that we removed the stop words, i.e. he, she, they, a, I. After that, we used a Lemmatizer that truncates words into their proper forms to prevent counting the same word in different forms, i.e. -ing, -s, -ed. It was re-vectorized and passed through the same Logistic Regression function, and the score improved.\n",
    "\n",
    "I also ran the LinearSVM because I was interested in finding out whether using a different model would yield any scores that were significantly different from the results we had achieved above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
